{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde61245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from 'breast_cancer_data.csv'\n",
      "Diagnosis column mapped to numerical values (M:0, B:1).\n",
      "\n",
      "--- Data Collection & Loading Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Data Collection & Loading\n",
    "# Load the dataset from the CSV file\n",
    "# Ensure the CSV file is in the same directory as your notebook or provide the full path\n",
    "try:\n",
    "    data_frame = pd.read_csv('breast_cancer_data.csv')\n",
    "    print(\"Dataset loaded successfully from 'breast_cancer_data.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'breast_cancer_data.csv' not found. Please ensure the CSV file is in the correct directory.\")\n",
    "    # Fallback to sklearn dataset if CSV is not found, for demonstration purposes\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    breast_cancer_data = load_breast_cancer()\n",
    "    data_frame = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "    data_frame['diagnosis'] = breast_cancer_data.target\n",
    "    print(\"Loaded Breast Cancer dataset from sklearn as a fallback.\")\n",
    "\n",
    "# Handle the 'id' column if it exists and is not needed for prediction\n",
    "if 'id' in data_frame.columns:\n",
    "    data_frame = data_frame.drop(columns='id', axis=1)\n",
    "\n",
    "# Convert 'diagnosis' column (M/B) to numerical (0/1)\n",
    "# 'M' (Malignant) will be 0, 'B' (Benign) will be 1\n",
    "# This mapping aligns with the prediction output interpretation in the PDF (0 for Malignant)\n",
    "data_frame['diagnosis'] = data_frame['diagnosis'].map({'M': 0, 'B': 1})\n",
    "print(\"Diagnosis column mapped to numerical values (M:0, B:1).\")\n",
    "\n",
    "print(\"\\n--- Data Collection & Loading Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d642cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the dataset:\n",
      "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          0        17.99         10.38          122.80     1001.0   \n",
      "1          0        20.57         17.77          132.90     1326.0   \n",
      "2          0        19.69         21.25          130.00     1203.0   \n",
      "3          0        11.42         20.38           77.58      386.1   \n",
      "4          0        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Last 5 rows of the dataset:\n",
      "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "94          0       15.060         19.83          100.30      705.6   \n",
      "95          0       20.260         23.03          132.40     1264.0   \n",
      "96          1       12.180         17.84           77.79      451.1   \n",
      "97          1        9.787         19.94           62.11      294.5   \n",
      "98          1       11.600         12.84           74.34      412.6   \n",
      "\n",
      "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "94          0.10390           0.15530        0.170000             0.088150   \n",
      "95          0.09078           0.13130        0.146500             0.086830   \n",
      "96          0.10450           0.07057        0.024900             0.029410   \n",
      "97          0.10240           0.05301        0.006829             0.007937   \n",
      "98          0.08983           0.07525        0.041960             0.033500   \n",
      "\n",
      "    symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "94         0.1855  ...         18.23          24.23           123.50   \n",
      "95         0.2095  ...         24.22          31.59           156.10   \n",
      "96         0.1900  ...         12.83          20.92            82.14   \n",
      "97         0.1350  ...         10.92          26.29            68.81   \n",
      "98         0.1620  ...         13.06          17.16            82.96   \n",
      "\n",
      "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "94      1025.0            0.1551            0.42030          0.52030   \n",
      "95      1750.0            0.1190            0.35390          0.40980   \n",
      "96       495.2            0.1140            0.09358          0.04980   \n",
      "97       366.1            0.1316            0.09473          0.02049   \n",
      "98       512.5            0.1431            0.18510          0.19220   \n",
      "\n",
      "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "94               0.21150          0.2834                  0.08234  \n",
      "95               0.15730          0.3689                  0.08368  \n",
      "96               0.05882          0.2227                  0.07376  \n",
      "97               0.02381          0.1934                  0.08988  \n",
      "98               0.08449          0.2772                  0.08756  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Number of rows and columns (shape): (99, 31)\n",
      "\n",
      "Information about the dataset (info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                99 non-null     int64  \n",
      " 1   radius_mean              99 non-null     float64\n",
      " 2   texture_mean             99 non-null     float64\n",
      " 3   perimeter_mean           99 non-null     float64\n",
      " 4   area_mean                99 non-null     float64\n",
      " 5   smoothness_mean          99 non-null     float64\n",
      " 6   compactness_mean         99 non-null     float64\n",
      " 7   concavity_mean           99 non-null     float64\n",
      " 8   concave points_mean      99 non-null     float64\n",
      " 9   symmetry_mean            99 non-null     float64\n",
      " 10  fractal_dimension_mean   99 non-null     float64\n",
      " 11  radius_se                99 non-null     float64\n",
      " 12  texture_se               99 non-null     float64\n",
      " 13  perimeter_se             99 non-null     float64\n",
      " 14  area_se                  99 non-null     float64\n",
      " 15  smoothness_se            99 non-null     float64\n",
      " 16  compactness_se           99 non-null     float64\n",
      " 17  concavity_se             99 non-null     float64\n",
      " 18  concave points_se        99 non-null     float64\n",
      " 19  symmetry_se              99 non-null     float64\n",
      " 20  fractal_dimension_se     99 non-null     float64\n",
      " 21  radius_worst             99 non-null     float64\n",
      " 22  texture_worst            99 non-null     float64\n",
      " 23  perimeter_worst          99 non-null     float64\n",
      " 24  area_worst               99 non-null     float64\n",
      " 25  smoothness_worst         99 non-null     float64\n",
      " 26  compactness_worst        99 non-null     float64\n",
      " 27  concavity_worst          99 non-null     float64\n",
      " 28  concave points_worst     99 non-null     float64\n",
      " 29  symmetry_worst           99 non-null     float64\n",
      " 30  fractal_dimension_worst  99 non-null     float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 24.1 KB\n",
      "\n",
      "Missing values per column:\n",
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics of the dataset (describe()):\n",
      "       diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  99.000000    99.000000     99.000000       99.000000    99.000000   \n",
      "mean    0.353535    14.710687     19.691414       96.491313   703.907071   \n",
      "std     0.480500     3.366163      3.778299       23.304598   321.722389   \n",
      "min     0.000000     8.196000     10.380000       51.710000   201.900000   \n",
      "25%     0.000000    12.455000     16.680000       81.970000   476.500000   \n",
      "50%     0.000000    14.250000     20.250000       94.250000   644.800000   \n",
      "75%     1.000000    17.170000     22.150000      114.600000   921.050000   \n",
      "max     1.000000    25.220000     27.540000      171.500000  1878.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count        99.000000         99.000000       99.000000            99.000000   \n",
      "mean          0.102086          0.126702        0.114963             0.063855   \n",
      "std           0.013210          0.061421        0.079235             0.038294   \n",
      "min           0.073550          0.037660        0.000692             0.004167   \n",
      "25%           0.092935          0.079625        0.041735             0.029110   \n",
      "50%           0.101600          0.120600        0.108000             0.066060   \n",
      "75%           0.110550          0.157700        0.167000             0.087670   \n",
      "max           0.142500          0.345400        0.375400             0.184500   \n",
      "\n",
      "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "count      99.000000  ...     99.000000      99.000000        99.000000   \n",
      "mean        0.193122  ...     17.563828      26.556869       116.682121   \n",
      "std         0.030974  ...      4.793332       5.714053        33.865531   \n",
      "min         0.135000  ...      8.964000      12.490000        57.260000   \n",
      "25%         0.172000  ...     14.170000      22.410000        91.410000   \n",
      "50%         0.189600  ...     16.570000      27.260000       110.600000   \n",
      "75%         0.208950  ...     20.920000      30.890000       140.600000   \n",
      "max         0.304000  ...     30.000000      40.680000       211.700000   \n",
      "\n",
      "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count    99.000000         99.000000          99.000000        99.000000   \n",
      "mean   1010.703030          0.142280           0.331117         0.357051   \n",
      "std     548.474567          0.023056           0.205870         0.238179   \n",
      "min     242.200000          0.093870           0.046190         0.001845   \n",
      "25%     608.300000          0.126600           0.176950         0.171700   \n",
      "50%     830.900000          0.143100           0.277600         0.315500   \n",
      "75%    1326.500000          0.157900           0.425100         0.523850   \n",
      "max    2615.000000          0.209800           1.058000         1.252000   \n",
      "\n",
      "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "count             99.000000       99.000000                99.000000  \n",
      "mean               0.145411        0.324106                 0.092156  \n",
      "std                0.068603        0.080852                 0.023935  \n",
      "min                0.011110        0.156500                 0.055040  \n",
      "25%                0.079185        0.272850                 0.076120  \n",
      "50%                0.155600        0.306300                 0.087560  \n",
      "75%                0.191550        0.369400                 0.103450  \n",
      "max                0.286700        0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "\n",
      "Distribution of the target variable ('diagnosis'):\n",
      "diagnosis\n",
      "0    64\n",
      "1    35\n",
      "Name: count, dtype: int64\n",
      "Value 0 represents Malignant tumors, Value 1 represents Benign tumors.\n",
      "\n",
      "--- Exploratory Data Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Display the first five rows of the dataset\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(data_frame.head())\n",
    "\n",
    "# Display the last five rows of the dataset\n",
    "print(\"\\nLast 5 rows of the dataset:\")\n",
    "print(data_frame.tail())\n",
    "\n",
    "# Use .shape to check the number of rows and columns\n",
    "print(f\"\\nNumber of rows and columns (shape): {data_frame.shape}\")\n",
    "\n",
    "# Use .info() for an overview of column types and non-null values\n",
    "print(\"\\nInformation about the dataset (info()):\")\n",
    "data_frame.info()\n",
    "\n",
    "# Check for missing values using .isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(data_frame.isnull().sum())\n",
    "\n",
    "# Display summary statistics with .describe()\n",
    "print(\"\\nSummary statistics of the dataset (describe()):\")\n",
    "print(data_frame.describe())\n",
    "\n",
    "# Analyze the target variable distribution using .value_counts()\n",
    "print(\"\\nDistribution of the target variable ('diagnosis'):\")\n",
    "print(data_frame['diagnosis'].value_counts())\n",
    "print(\"Value 0 represents Malignant tumors, Value 1 represents Benign tumors.\")\n",
    "\n",
    "print(\"\\n--- Exploratory Data Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ea9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of features (X): (99, 30)\n",
      "Shape of target (Y): (99,)\n",
      "\n",
      "First 5 rows of Features (X):\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "First 5 values of Target (Y):\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: diagnosis, dtype: int64\n",
      "\n",
      "--- Data Preprocessing Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Data Preprocessing\n",
    "\n",
    "# Separate the features (X) and target variable (Y)\n",
    "# All columns except 'diagnosis' are features\n",
    "X = data_frame.drop(columns='diagnosis', axis=1)\n",
    "Y = data_frame['diagnosis']\n",
    "\n",
    "print(f\"\\nShape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (Y): {Y.shape}\")\n",
    "print(\"\\nFirst 5 rows of Features (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nFirst 5 values of Target (Y):\")\n",
    "print(Y.head())\n",
    "\n",
    "print(\"\\n--- Data Preprocessing Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de33af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train: (79, 30)\n",
      "Shape of X_test: (20, 30)\n",
      "Shape of Y_train: (79,)\n",
      "Shape of Y_test: (20,)\n",
      "\n",
      "--- Dataset Splitting Complete ---\n",
      "\n",
      "--- Applying Feature Scaling ---\n",
      "Features scaled successfully.\n",
      "Shape of X_train_scaled: (79, 30)\n",
      "Shape of X_test_scaled: (20, 30)\n",
      "\n",
      "--- Feature Scaling Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 4. Splitting the Dataset\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "print(f\"Shape of Y_test: {Y_test.shape}\")\n",
    "\n",
    "print(\"\\n--- Dataset Splitting Complete ---\")\n",
    "\n",
    "print(\"\\n--- Applying Feature Scaling ---\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully.\")\n",
    "print(f\"Shape of X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"Shape of X_test_scaled: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\n--- Feature Scaling Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b2059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression model trained successfully.\n",
      "\n",
      "--- Model Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Model Training\n",
    "\n",
    "# Create a Logistic Regression model instance\n",
    "model = LogisticRegression(max_iter=2000) # Increased max_iter for convergence, common for logistic regression\n",
    "                                         # especially with varied feature scales.\n",
    "                                         # For very large datasets, consider using a solver like 'saga' or 'liblinear'\n",
    "                                         # with specific penalties.\n",
    "\n",
    "# Train the logistic regression model using the training data\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "print(\"\\nLogistic Regression model trained successfully.\")\n",
    "\n",
    "print(\"\\n--- Model Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2d37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on training data = 0.9873\n",
      "Accuracy on test data     = 0.9500\n",
      "\n",
      "--- Model Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 6. Model Evaluation\n",
    "\n",
    "# On training data:\n",
    "# Make predictions on the SCALED training data\n",
    "X_train_prediction = model.predict(X_train_scaled) # IMPORTANT: Use X_train_scaled here\n",
    "\n",
    "# Calculate the accuracy score for training data\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "print(f\"\\nAccuracy on training data = {training_data_accuracy:.4f}\")\n",
    "\n",
    "# On testing data:\n",
    "# Make predictions on the SCALED testing data\n",
    "X_test_prediction = model.predict(X_test_scaled) # IMPORTANT: Use X_test_scaled here\n",
    "\n",
    "# Calculate the accuracy score for testing data\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "print(f\"Accuracy on test data     = {test_data_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n--- Model Evaluation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc070698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw prediction output: 1\n",
      "The Breast Cancer is Benign\n",
      "\n",
      "Raw prediction for a known Malignant sample: 0\n",
      "The Breast Cancer is Malignant (Correctly Predicted)\n",
      "\n",
      "--- Predictive System Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\文档\\project\\breast_cancer_prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ayush\\OneDrive\\文档\\project\\breast_cancer_prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. Building a Predictive System\n",
    "\n",
    "# Input a sample data point (ensure it has 30 features as per the dataset)\n",
    "# This sample data point corresponds to a 'B' (Benign) diagnosis from your CSV (id 8510426)\n",
    "input_data = (13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,\n",
    "              0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,\n",
    "              15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)\n",
    "\n",
    "# Convert the input data into a NumPy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# Reshape the numpy array as we are predicting for one data point\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
    "\n",
    "# IMPORTANT: Scale the single input data point using the SAME scaler fitted on the training data\n",
    "input_data_scaled = scaler.transform(input_data_reshaped)\n",
    "\n",
    "# Predict the output using the trained model (now expects scaled input)\n",
    "prediction = model.predict(input_data_scaled) # IMPORTANT: Use input_data_scaled here\n",
    "print(f\"\\nRaw prediction output: {prediction[0]}\")\n",
    "\n",
    "# Interpret the prediction\n",
    "if (prediction[0] == 0):\n",
    "  print('The Breast Cancer is Malignant')\n",
    "else:\n",
    "  print('The Breast Cancer is Benign')\n",
    "\n",
    "# Test with a known Malignant sample from your CSV (e.g., id 842302)\n",
    "malignant_sample = (17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,\n",
    "                    1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,\n",
    "                    25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189)\n",
    "\n",
    "malignant_sample_reshaped = np.asarray(malignant_sample).reshape(1, -1)\n",
    "\n",
    "# IMPORTANT: Scale the malignant sample using the SAME scaler\n",
    "malignant_sample_scaled = scaler.transform(malignant_sample_reshaped)\n",
    "\n",
    "malignant_prediction = model.predict(malignant_sample_scaled) # IMPORTANT: Use malignant_sample_scaled here\n",
    "\n",
    "print(f\"\\nRaw prediction for a known Malignant sample: {malignant_prediction[0]}\")\n",
    "if (malignant_prediction[0] == 0):\n",
    "  print('The Breast Cancer is Malignant (Correctly Predicted)')\n",
    "else:\n",
    "  print('The Breast Cancer is Benign (Incorrectly Predicted)')\n",
    "\n",
    "print(\"\\n--- Predictive System Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8576b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
